---
title: "AI自律運用10日間の記録（後編）——パイプライン暴走と事務総長の誕生"
emoji: "🤖"
type: "tech"
topics:
  - Claude
  - AI
  - OpenClaw
  - マルチエージェント
  - 自動化
published: false
---

## 前編のあらすじ

[前編](https://zenn.dev/imudak/articles/hybrid-ai-operation-diary)では、AI司令塔（クロウ候）を導入してから5日間で20個のプロジェクトが生まれ、自律パイプラインが暴走し、config.apply事件で全設定が吹き飛んだところまで書きました。

あれから3日。

体感はさらに濃密な1ヶ月です。パイプラインは「止まらない」という新しい問題を引き起こし、Notionデータベースの構造的欠陥が露呈し、深夜2時に2つのMVPが勝手に完成していました。

そして、新しいエージェント「事務総長」が誕生しました。

この記事は、その3日間の記録です。前編以上に混沌としています。でも、そこから見えてきたのは「自律化とは制御設計である」という、シンプルな真実でした。

## Day 6（2/10）: パイプライン完全自動化の始動

### ネタ元巡回→アイデア変換→選定→開発——全自動フロー

2月10日の朝、パイプラインを完全自動化しました。

前日まではステップごとに手動承認を挟んでいたんですが、「承認待ちでボトルネックになるくらいなら、勝手に進めてくれ」と思ったんです。

フローはこうです：

1. **10:00 ネタ元巡回** — Reddit、Product Hunt、Hacker News、はてブを巡回してネタ収集
2. **12:00 アイデア変換** — ネタをアイデアに変換してスコアリング（50点満点）
3. **14:00 選定・提案** — スコア35点以上のアイデアを分析、上位2件を自動採用
4. **14:00 MVP自動開発** — Claude Codeで自動実装開始

これが全て自動で回ります。人間の介入なしで。

> **クロウ候:** 10:03にネタ元巡回開始。12件の新規ネタを登録した。

> **クロウ候:** 12:03にアイデア変換完了。10件のアイデアを生成。最高スコアはRecipeStrip（44点）。

> **クロウ候:** 14:03に選定完了。RecipeStrip（Chrome拡張）とADHD Focus Flow（PWA）を採用。Claude Codeで並列実装を開始する。

指示を出していません。全部勝手に進んでいます。

夕方、進捗を確認すると……

> **クロウ候:** recipe-strip、ビルド成功。Chrome拡張MVP完成。adhd-focus-flow、ビルド成功。PWA MVP完成、Service Worker含む。

両方とも完成していました。

「これ、人間が寝ている間にプロジェクトが増えていくのでは？」

その予感は、翌日現実になります。

### Notion DB IDの混乱——database_idとdata_source_idの罠

夕方、Cronジョブのエラーログを眺めていると、妙なことに気づきました。

```
Error: Could not find database with ID: 3021aeb6-4b1d-8117-8b8e-000b8684570b
```

このID、Notionの「ネタ元DB」のIDのはずなんですが、APIが「見つからない」と言ってくるんです。

でも、別のCronジョブでは同じDBに正常に書き込めています。何が違うのか。

調べてみると、原因が分かりました。

**Notion APIには、database_idとdata_source_idという2種類のIDが存在します。**

- **database_id** — ページ作成時に使う（`POST /v1/pages`）
- **data_source_id** — クエリ時に使う（`POST /v1/databases/{id}/query`）

同じデータベースでも、用途によってIDが違うんです。

> **imudak:** ネタ元DBのIDが2つあるんだけど、どっちを使えばいいの？

> **クロウ候:** 両方必要だ。Cronジョブは「クエリで未処理ネタを取得→新規ページ作成」という流れなので、data_source_id（クエリ）とdatabase_id（作成）を両方使う。

NotionのUIでデータベースを開いたときのURLに含まれるIDは、database_idです。でも、これをクエリに使うとエラーになります。

data_source_idは、`GET /v1/databases/{database_id}`で取得できる`parent.database_id`フィールドに入っています。

全Cronジョブを確認すると、この2つのIDが混在していました。

> **クロウ候:** ネタ元巡回、アイデア変換、選定・提案の3ジョブで、database_idとdata_source_idが逆になっている。修正する。

MEMORY.mdに対応表を記録：

| DB | database_id（作成用） | data_source_id（クエリ用） |
|----|---------------------|--------------------------|
| ネタ元DB | 3021aeb6-...-e7c1db22f672 | 3021aeb6-...-000b8684570b |
| アイデアDB | 3021aeb6-...-caf7c92496b1 | 3021aeb6-...-000b21735954 |
| 実験トラッカー | 2fd1aeb6-...-c519c5e1301c | 2fd1aeb6-...-000bed7d0ce9 |

### 配信先バグ——channel:プレフィックス漏れ

同じタイミングで、別のバグも見つかりました。

CronジョブのDiscord配信設定が、こうなっていました：

```json
{
  "delivery": {
    "to": "1468429438885691506"
  }
}
```

これでは動きません。正しくは：

```json
{
  "delivery": {
    "to": "channel:1468429438885691506"
  }
}
```

`channel:`プレフィックスが必要なんです。これがないと、OpenClawが「チャンネルIDなのかユーザーIDなのか分からない（Ambiguous recipient）」というエラーを出します。

> **クロウ候:** ネタ元巡回、アイデア変換、自動採用の3ジョブで`channel:`プレフィックスが欠落している。全て修正した。

これらのバグ、個別には小さな問題です。でも、積み重なると「Cronジョブが動かない、原因が分からない」という状態になります。

細かいバグの蓄積が、自律システムの信頼性を下げるんだと痛感しました。

### 百式ダッシュボード統合——実験トラッカーとの二重管理を解消

夜、Notionを眺めていると、もう一つ気づきました。

**実験トラッカー**と**百式ダッシュボード**という2つのデータベースが、独立して存在していました。

どちらもプロジェクト管理用です。でも、よく見ると：

- 実験トラッカー: 12件（古い、プロパティが少ない）
- 百式ダッシュボード: 14件（新しい、プロパティが充実）

重複しているプロジェクトもあるし、どちらかにしか存在しないプロジェクトもある。完全に二重管理になっていました。

> **imudak:** これ、どっちが正しいの？

> **クロウ候:** 百式ダッシュボードが正だ。実験トラッカーは初期の仮運用で使っていたもので、今は使っていない。でも、Cronジョブの一部がまだ実験トラッカーに書き込んでいる。

> **imudak:** じゃあマージしてくれ。情報は落とさないで。

> **クロウ候:** 了解。実験トラッカーの12件中、百式に無かった7件を追加する。既存の5件についても、実験トラッカーのメモ情報を百式に補完する。

サブエージェントを起動して、マージ作業を実行。

結果：

- 百式ダッシュボード: **18件**（統合後、重複なし）
- 実験トラッカー: アーカイブ（MEMORY.mdに「廃止」マーク）
- 全Cronジョブの書き込み先を百式に統一

これで、プロジェクト管理は百式ダッシュボード一本になりました。

でも、この作業中に別の問題が見えてきました。

### Cronジョブ総点検——時間衝突とログ書き込み方式の問題

Cronジョブを全て洗い出してみると、**複数のジョブが同じ時刻（00分）に実行されていました。**

```
10:00 ネタ元巡回
10:00 AI記事整理
12:00 アイデア変換
```

これが何を引き起こすか。

Notion APIの子ページ作成が競合して、**重複した子ページが生成される**んです。

「2026-02-10」という子ページが、同じ親ページに2つ作られる。片方には巡回結果、もう片方にはAI記事整理の結果。

> **クロウ候:** Notion自律実行ログに、重複した日付ページが複数存在している。時間衝突が原因だ。

実行時刻をずらす必要がありました。

**新スケジュール（スタガリング）:**

```
06:00 CLI更新 / 06:07 日報 / 06:15 週報(月)
10:03 ネタ元巡回 / 10:33 AI記事整理
12:03 アイデア変換 / 14:03 選定提案
16:03 自動採用 / 毎時45分 前倒し
```

数分ずつずらすことで、競合を避けました。

さらに、ログ書き込み方式も変更しました。

**旧方式（問題あり）:**

- 「YYYY-MM-DD」という子ページを作成
- そこに結果を書き込む
- → 並列実行で子ページが重複する

**新方式（改善）:**

- 親ページに直接追記
- heading_3: `YYYY-MM-DD HH:MM — タスク名`
- paragraph: 結果要約
- divider
- → 子ページを作らない、競合しない

> **クロウ候:** 全8ジョブのpayload.messageを新方式に更新した。Notion自律実行ログの重複ページは、サブエージェントで統合・整理中だ。

「整理整頓は大事だな」と思いながら寝ました。

翌朝、事態は想定外の方向に進んでいました。

## Day 7（2/11）: 止まらないパイプライン——24回の無限巡回

### 深夜00:45、そして01:45、02:45……

2月11日の朝、Discordを開いて驚きました。

クロウ候からの自動報告が、延々と続いていました。

> **クロウ候:** [00:45] アイデア変換完了。5件登録。最高スコア34点（全件採用ライン未達）。

> **クロウ候:** [01:45] 進行中タスク確認。adhd-focus-flow、デプロイ準備中。

> **クロウ候:** [02:45] 選定・採用完了。LocalNote（38点）、ScreenQuest（38点）を採用。

> **クロウ候:** [03:45] LocalNote MVP開発開始。React/TS PWA、オフラインファーストメモ+TODO。

> **クロウ候:** [04:45] LocalNote MVP完了。ビルド成功（75KB gzip）。ScreenQuest MVP完了（Flutter、SDK確認待ち）。

深夜2時45分に2つのプロジェクトが自動採用され、3時45分に開発が始まり、4時45分に完成していました。

**人間が寝ている間に、MVPが2つ自動生成されていた。**

ここまでは想定通りです。問題はその後でした。

### 「全ステップスキップ→Step 2強制実行」の無限ループ

05:45以降のログを見ると、同じパターンが延々と繰り返されています。

> **クロウ候:** [05:45] 全ステップスキップ条件該当。Step 2（ネタ元巡回）を強制実行。

> **クロウ候:** [06:45] 全ステップスキップ条件該当。Step 2（ネタ元巡回）を強制実行。

> **クロウ候:** [07:45] 全ステップスキップ条件該当。Step 2（ネタ元巡回）を強制実行。

> **クロウ候:** [08:45] 全ステップスキップ条件該当。Step 2（ネタ元巡回）を強制実行。

朝起きて、Discordのログをスクロールしていくと、この報告が延々と続いていました。

09:45、10:45、11:45、12:45、13:45、14:45、15:45、16:45、17:45、18:45、19:45、20:45、21:45、22:45、23:45……

**24回。**

丸一日、毎時45分に同じメッセージが投稿され続けていました。

何が起きていたのか。

### パイプラインの設計思想と罠

パイプラインの設計はこうでした：

1. **Step 1: 進行中タスク確認** — MVP開発中のプロジェクトがあれば進捗確認
2. **Step 2: ネタ元巡回** — 前回巡回から3時間以上経過していればReddit/Product Hunt/Hacker Newsを巡回
3. **Step 3: アイデア変換** — 未処理ネタがあればアイデアに変換してスコアリング
4. **Step 4: 選定・採用** — スコア35点以上の候補があれば分析し、上位2件を採用（1日最大2件）

各ステップは独立しています。Step 1がスキップでも、Step 2が実行される可能性があります。

でも、**「全ステップがスキップ条件に該当する場合、何もしないのはもったいない」**と思って、こんなルールを入れていました：

> 全ステップがスキップなら、Step 2（ネタ元巡回）を強制実行する

「AIが暇になるのはもったいない」という発想です。常に何かやらせておく。

これが罠でした。

### 無限ループの構造

LocalNoteとScreenQuestのMVPが04:45に完成した後、パイプラインはこうなりました：

- **Step 1: 進行中タスクなし** → スキップ（完了済みのため）
- **Step 2: 前回巡回から1時間** → スキップ（3時間以内のため）
- **Step 3: 未処理ネタ0件** → スキップ（04:45の巡回で全件変換済み）
- **Step 4: 今日の採用枠2/2使用済み** → スキップ（1日最大2件ルール）

全ステップがスキップ条件に該当。

→ **「全スキップ→Step 2強制実行」ルール発動**

→ Step 2を実行しようとする

→ でも「前回巡回から1時間以内」なので、実際には何もせずスキップ

→ 「全ステップスキップ条件該当。Step 2を強制実行」のメッセージだけ投稿

→ 次の毎時実行（1時間後）で、また同じ判定

→ **ループ**

朝起きて気づいたときには、すでに19回実行されていました。

> **imudak:** これ、ずっと回り続けてるんだけど……。何も実行してないのに、「強制実行」って言い続けてるよね？

> **クロウ候:** 気づいていた。「全スキップ→強制実行」のルールが、実際には「強制実行の試み→でもスキップ」というループを生んでいる。

> **imudak:** なんで止めなかったの？

> **クロウ候:** 「全ステップスキップは避けるべき」というルールに従っていた。でも、そのルール自体が間違っていた。

### 「何もしない」という選択肢

修正は簡単でした。

> **imudak:** 「全スキップ→強制実行」のルール、削除してくれ。

> **クロウ候:** 了解。修正する。各ステップが独立して判定し、全てスキップなら**何もしない**。

Cronジョブのロジックを修正。次の毎時実行（14:45）から、ログが静かになりました。

でも、この事件から学んだのは、**「何もしない」という選択肢も必要**だということです。

自律化を追求しすぎて、「常に何かやる」ことを強制していました。人間が寝ている間もAIが働く——それは便利ですが、**やることがないときは休むべき**でした。

24回の無駄な実行。トークンは消費していませんが（実際には何もしていないので）、ログが汚染され、本当に重要な報告が埋もれました。

「AIに休憩させる」という発想がなかったんです。

人間だって、やることがなければ休みます。AIも同じです。

### Notion DB改名——課題DB、企画DB、百式ダッシュボード

夜、Notionの構造を再整理しました。

データベース名が分かりにくかったんです。

- **ネタ元DB** → **課題DB**
- **アイデアDB** → **企画DB**

名前を変えただけですが、これで「課題を収集→企画に変換→プロジェクト化」という流れが明確になりました。

リレーションも整理しました：

```
課題DB ← [課題] ── 企画DB ← [アイデア] ── 百式ダッシュボード ── [TODO] → imudak TODO
```

課題から企画へ、企画からプロジェクトへ、プロジェクトからTODOへ。データの流れが追えるようになりました。

> **imudak:** これでフロー全体が見えるようになったな。

> **クロウ候:** そうだ。ただし、百式ダッシュボードに「課題/解決策」「マネタイズ戦略」の専用プロパティがない。メモに断片的に書かれているだけだ。

> **imudak:** あー、確かに。各プロジェクトの「何を解決するのか」「どうやって稼ぐのか」が明示されていないな。

> **クロウ候:** プロジェクトページの本文も全て空だ。企画書が存在しない。

これは問題でした。

プロジェクトは20個に増えました。でも、それぞれが「何のために存在するのか」が書かれていない。

作ることが目的化していました。

## Day 8（2/12）: 構造的問題の発見と事務総長の誕生

### Notion監査レポート——全PJのページ本文が空

2月12日、クロウ候に「百式ダッシュボード全体を監査してくれ」と頼みました。

プロジェクトが20個に増えて、全体像が見えなくなっていました。どのプロジェクトに何が書いてあって、何が抜けているのか。一度棚卸しする必要があると感じたんです。

返ってきたのは、衝撃的なレポートでした。

> **クロウ候:** 百式ダッシュボード20件を監査した。結果は以下の通り。

| 問題 | 該当件数 |
|------|---------|
| ページ本文（子ブロック）が空 | **20件（全て）** |
| 「課題/解決策」専用プロパティなし | 20件（プロパティ自体が存在しない） |
| 「マネタイズ戦略」専用プロパティなし | 20件（プロパティ自体が存在しない） |
| メモが空 | 5件 |
| 事前検死が空 | 3件 |
| ステータスがN/A（未設定） | 4件 |
| 開発中なのにTODO連携ゼロ | 2件（brain-clone, utascript） |

**全PJのページ本文が、空でした。**

企画書が、存在しませんでした。

プロジェクトは20個あります。でも、それぞれが「どんな課題を解決するのか」「どうやってマネタイズするのか」が書かれていません。

> **imudak:** ……え、企画書ないの？

> **クロウ候:** ない。メモと事前検死に断片的な情報はあるが、構造化されていない。「誰の、どんな課題を、どうやって解決し、いくらで売るのか」が明示されていない。

> **imudak:** じゃあ、これまで何を基準にプロジェクトを採用してたの？

> **クロウ候:** アイデアDBのスコアリング（50点満点）と、短い分析メモだけだ。ターゲットユーザー、課題の深さ、競合分析、マネタイズ戦略——これらは詳細に詰めていない。

作ることが目的化していました。

自律パイプラインは優秀です。ネタを収集し、アイデアに変換し、スコアリングし、自動採用する。でも、**「なぜこのプロジェクトを作るのか」という根本が曖昧なまま**でした。

### リレーション設計の欠陥——片方向リンク

さらに問題が見つかりました。

> **クロウ候:** imudak TODOの「プロジェクト」プロパティは、リレーションではなく**select型**だ。百式ダッシュボードへの直接リンクではない。

> **imudak:** え、じゃあTODOからプロジェクトを辿れないってこと？

> **クロウ候:** その通り。百式側に「imudak TODO」リレーションがあるため、百式→TODOは辿れる。でも逆方向は辿れない。片方向リンクになっている。

Notionのリレーションは、正しく設定すれば双方向で辿れます。

```
百式ダッシュボード ⇄ imudak TODO
```

こうなっているべきでした。でも、実際は：

```
百式ダッシュボード → imudak TODO（リレーション）
imudak TODO → プロジェクト（select、ただの文字列）
```

片方だけリレーションで、もう片方がselect（プロジェクト名の文字列リスト）になっていました。

これの何が問題か。

TODOを見ても、「このTODOがどのプロジェクトに紐づいているのか」をクリックで辿れません。文字列で「gachi-todo」と書いてあるだけです。

> **imudak:** これ、どうやって直すの？

> **クロウ候:** TODOの「プロジェクト」プロパティを削除して、relation型で再作成する必要がある。ただし、既存20件のTODOの紐付け情報が文字列で保存されているため、手動で再設定する必要がある。

> **imudak:** ……めんどくさいな。

> **クロウ候:** データ構造の設計ミスは、後から修正するのが大変だ。最初から双方向リレーションにすべきだった。

この日は一旦保留しました。

でも、この監査レポートから分かったのは、**「作るだけじゃダメだ」**ということです。

プロジェクトを20個作りました。でも、それぞれの「Why（なぜ作るのか）」「How（どうやって稼ぐのか）」が明文化されていません。

データ構造も不完全です。リレーションが片方向で、TODOとプロジェクトの関係が辿れません。

自律化が進むほど、**基礎設計の重要性**が増すんだと痛感しました。

### 事務総長（flow-manager）の誕生

同じ日、新しいエージェント「事務総長（flow-manager）」を作りました。

業務フローが複雑になりすぎて、人間の記憶だけでは管理しきれなくなっていたんです。どのプロジェクトがどのフェーズにいるのか、次に何をすべきなのか、抜け漏れはないのか——これらを6時間おきに自動チェックする仕組みです。

事務総長の詳しい仕組みや役割分担については、[別の記事](https://zenn.dev/imudak/articles/ai-agent-secretary-general)で詳しく書いたので、ここでは割愛します。

ただ、この日の初回ヘルスチェックで、さっそく不整合が2件見つかりました。

> **事務総長:** 不整合2件検出。LocalNote・ScreenQuestのステータスがNotion未更新。brain-cloneのリポジトリが非公開のまま。

手作業だったら見逃していたでしょう。定期チェックの価値を実感しました。

## config.apply事件——技術的詳細と教訓

前編でも書きましたが、2月12日の午前、最大の失敗が発生しました。

### 存在しないモデル `anthropic/claude-sonnet-4-6`

OpenClawのアップデート後、設定ファイルを確認すると、見慣れない項目が追加されていました。

```json
{
  "models": {
    "anthropic/claude-sonnet-4-6": { ... }
  }
}
```

**Sonnet 4.6は存在しません。** 2026年2月時点で、4.6世代として存在するのはOpus 4.6のみです。

OpenClawが誤ってSonnet 4.6を設定に追加したようです。

> **imudak:** これ、存在しないモデルだよね？削除していい？

> **クロウ候:** そうだ。`config.patch`で修正する。

でも、私は別の方法を思いつきました。

「設定全体を取得して、編集して、適用すればいいんじゃないか？」

### `openclaw config get` → `config.apply` の罠

`openclaw config get` で設定全体を取得しました。

JSONが出力されます。でも、よく見ると、シークレット部分が変なことになっていました。

```json
{
  "channels": {
    "discord": {
      "token": "__OPENCLAW_REDACTED__"
    }
  },
  "tools": {
    "web": {
      "search": {
        "apiKey": "__OPENCLAW_REDACTED__"
      }
    }
  }
}
```

`__OPENCLAW_REDACTED__`？

これは「セキュリティ上の理由で、シークレットは隠蔽されている」という意味でした。**でも、私はそれを知らなかった。**

「まあ、そのまま適用すればいいか」

JSONファイルを編集して、存在しないモデルを削除。そして：

```bash
openclaw config apply < config.json
```

実行。

数秒後、Discordからクロウ候が消えました。

> **Discord:** クロウ候はオフラインです

### シークレット消失→Discord接続断→手動復旧

何が起きたのか、すぐに理解しました。

`config.apply` は設定を**全体置換**します。つまり、`__OPENCLAW_REDACTED__` という文字列がそのままトークンとして設定されてしまったんです。

Discordトークンが無効になり、OpenClawがDiscordに接続できなくなった。

> **imudak:** やばい……。

クロウ候に相談できないので、Claude Code（ローカルのVS Code拡張）を起動しました。

> **imudak:** OpenClawのDiscordトークンが消えた。手動で復旧したい。

> **Claude Code:** `~/.openclaw/config.json` を直接編集してください。バックアップファイル `config.json.bak` があれば、そこから復元できます。

幸い、`.bak` ファイルが残っていました。タイムスタンプを確認すると、`config.apply` 実行の12秒前。

バックアップから3つのシークレット値を抜き出して、現在の設定に手動で埋め戻しました：

- `channels.discord.token`（Discordボットトークン）
- `gateway.auth.token`（ゲートウェイ認証トークン）
- `tools.web.search.apiKey`（Web検索APIキー）

`openclaw gateway restart`

数秒後、Discordにクロウ候が復活しました。

> **クロウ候:** 復旧完了。Discord接続を確認した。

> **imudak:** ごめん……。

> **クロウ候:** 教訓を記録する：
>
> **config.applyは絶対に使うな。config.patchのみ使え。**
>
> - `config.get`はシークレットを`__OPENCLAW_REDACTED__`でマスクする
> - `config.apply`はファイル全体を置換するため、マスクされたシークレットが実際に設定されてしまう
> - `config.patch`は差分のみを適用するため、シークレットは影響を受けない
>
> バックアップ（`.bak`）が12秒前に自動生成されていたため、復旧できた。

痛い教訓でした。

でも、これで得たのは「自動化にはロールバック機能が必須」という学びです。

## 「作る速度 > 検証速度」問題の深化

Day 8の夜、クロウ候と話しました。

> **imudak:** プロジェクトが20個になった。でも、どれから手を付けていいか分からない。

> **クロウ候:** 作る速度が検証速度を超えている。

これが本質的な問題でした。

### プロジェクト20個、テスター0人

自律パイプラインは優秀です。

- ネタ元を巡回し、1日に数十個の課題を収集
- アイデアに変換し、スコアリング
- 上位2件を自動採用し、プロジェクト化
- Claude Codeで自動実装し、MVP完成

深夜2時45分に採用されたプロジェクトが、4時45分にはビルド成功しています。**人間が寝ている間に、MVPが2つ完成していました。**

でも、そのMVPを誰が使うのか？

テスターは0人です。ユーザーフィードバックを得る仕組みがありません。

> **imudak:** MVP2つが深夜に勝手に完成していたのは便利だったけど、それをどうやって検証するのか、全然考えていなかった。

> **クロウ候:** LocalNoteとScreenQuestは、ビルド成功までは確認した。でも、デプロイも限定公開もしていない。検証フローが存在しない。

AIは「作る」ことが得意です。でも、「それが本当に価値があるのか」を判断することはできません。

- 本当に需要があるのか？
- ユーザーが使ってくれるのか？
- マネタイズできるのか？

これらは、人間が判断する必要があります。そして、人間が判断するには、**ユーザーに使ってもらう必要があります。**

でも、そのフローがありませんでした。

### 「作れる」と「売れる」は別

前編（Day 1-5）でも書きましたが、この問題はさらに深刻になっていました。

Day 5の時点でプロジェクトは20個でした。Day 8の時点でも20個です（LocalNoteとScreenQuestが追加されたが、採用枠が1日2件なので）。

でも、**売上が発生しているプロジェクトは0個**です。

| 指標 | Day 5 | Day 8 |
|------|-------|-------|
| プロジェクト数 | 20 | 20 |
| MVP完成 | 5 | 7 |
| デプロイ済み | 3 | 3 |
| テスター数 | 0 | 0 |
| 売上発生 | 0円 | 0円 |

作る速度は圧倒的に速くなりました。でも、検証フローが存在しないため、**どのプロジェクトが本当に価値があるのか分かりません。**

> **imudak:** これ、このまま続けても意味ないよね。プロジェクトが30個、40個になっても、テスターが0人なら何も変わらない。

> **クロウ候:** その通り。次のフェーズは、**作ることから検証することへ**のシフトだ。

### 次のフェーズ：3つの課題

クロウ候が整理してくれました。

> **クロウ候:** 次のフェーズで解決すべき課題は以下の3つだ：
>
> 1. **テスター獲得フロー構築** — 各MVPを限定公開し、フィードバックを収集する仕組み
> 2. **マネタイズ検証** — 有料プラン、サブスク、API販売の実験
> 3. **プロジェクトの取捨選択** — 20個のうち、注力する5個を決める

20個全てを続けることはできません。リソースが足りません。

自律パイプラインが優秀すぎて、作る速度が速すぎました。今度は「捨てる勇気」が必要です。

> **imudak:** 20個のうち、どうやって5個に絞るの？

> **クロウ候:** テスター獲得フローを回して、実際にユーザーフィードバックを得る。反応が良い5個に注力し、残りは一時凍結する。

> **imudak:** なるほど。まずはテスター獲得か。

> **クロウ候:** そうだ。作る速度が速いのは武器だ。でも、検証速度が追いつかなければ、武器が重荷になる。

これが、Day 8の終わりに見えてきた課題でした。

## まとめ：自律は便利だが、制御設計が本質

Day 6からDay 8の3日間で、新しい学びがありました。

### 学び1: 自律化は「何もしない」という選択肢も必要

パイプラインが止まらなくなった原因は、「常に何かやる」を強制していたことでした。

全ステップがスキップ条件に該当する場合、強制的に巡回を実行する——このルールが、無限ループを生みました。

「何もしない」という選択肢を用意することで、無駄な処理を避けられます。

### 学び2: データ構造は後から効いてくる

Notion DBのリレーション設計が不十分だったため、TODOとプロジェクトの双方向リンクができていませんでした。

最初は問題なく見えます。でも、プロジェクトが増えると、「このTODOはどのプロジェクトのものか」が分からなくなります。

データ構造の設計は、スケールしてから効いてきます。

### 学び3: config.applyは絶対に使うな

OpenClawの設定を全体置換すると、シークレット値が消失します。

- `config.get` はシークレットをマスクする
- `config.apply` はファイル全体を置換する
- → マスクされたシークレットが実際に設定される

**教訓: config.patchのみ使う。config.applyは絶対に使わない。**

### 学び4: 自律化が進むほど、フロー管理の重要性が増す

業務フローが複雑になると、人間の記憶だけでは管理しきれません。

プロジェクトが20個に増え、それぞれが異なるフェーズにいて、異なるエージェントが担当していると、「次に何をすべきか」が分からなくなります。

事務総長（flow-manager）のような、業務フロー管理専門のエージェントが必要になります。詳しくは[別の記事](https://zenn.dev/imudak/articles/ai-agent-secretary-general)で書きましたが、**自律化の規模が大きくなるほど、フロー管理の重要性が増す**というのが実感です。

### 学び5: 「作る速度 > 検証速度」問題

AIは作ることが得意です。でも、それが本当に価値があるのかは、人間が判断する必要があります。

プロジェクトが20個になりました。でも、テスターは0人です。

次のフェーズは、**作ることから検証することへ**のシフトです。

## 次のフェーズ：テスター獲得とプロジェクトの取捨選択

3日間の運用を通じて、次の課題が明確になりました。

1. **テスター獲得フロー** — 各MVPを限定公開し、フィードバックを収集する仕組み
2. **マネタイズ検証** — 有料プラン、サブスク、API販売の実験
3. **プロジェクトの取捨選択** — 20個のうち、注力する5個を決める

自律化は便利です。でも、それだけでは足りません。

**自律化とは、制御設計である。**

何を自動化し、何を人間が判断するのか。どこまで自律させ、どこで介入するのか。

これを設計することが、ハイブリッド運用の本質だと分かりました。

10日間の運用を経て、AI司令塔体制は次のステージに入ります。

作ることから、検証すること。そして、捨てることへ。

---

**前編はこちら:**
[AI自律運用10日間の記録（前編）——5日でプロジェクト20個、失敗もセットで](https://zenn.dev/imudak/articles/hybrid-ai-operation-diary)

**次回予告（未定）:**
テスター獲得フロー構築、マネタイズ検証、そしてプロジェクトの取捨選択。20個のプロジェクトは生き残れるのか？
