---
title: "LLMに決定論的な処理をさせていた話 — jimuchoの誕生と文書肥大化の顛末"
emoji: "🔧"
type: "tech"
topics: ["ai", "workflow", "automation", "claude"]
published: false
---

## 前提 — 1人で40件のプロジェクトを回している

合同会社を1人で経営しながら、AIエージェント（Claudeベース）を使って40件超のプロジェクトを並走させています。Webアプリ、Chrome拡張、Flutterアプリ、業務自動化ツールなど種類はバラバラで、コードを書くのはほぼ全てAIです。

しばらく運用を続けていると、2つの設計ミスに気づきました。

1つ目は「LLMでやらなくていい処理にLLMを使っていた」こと。2つ目は「AIに指示を守らせようとして文書を増やしたら、逆に指示が守られなくなった」ことです。

どちらも運用コストを実際に上げていた問題で、対処の過程でいくつかの気づきがありました。気づいた順に書きます。

## LLMに決定論的な処理をさせていた

### 何をやっていたか

AIエージェントの運用を始めた頃、「AIなんだから何でもやらせられる」という感覚でいろいろな処理をAIセッションに投げていました。

- 日報生成（「今日の作業記録を読んでサマリーを作って」）
- DBの整合性チェック（「jimuchoのデータとNotion側のデータを見て、ズレを検出して」）
- 定期レポート（「先週完了したプロジェクト一覧をまとめて」）
- ステータス更新（「ビルドが通ったからこのPJのステータスを更新して」）

どれも「できてしまう」処理です。AIに指示すれば実行してくれます。問題は、これらが全てLLMを経由する必要がなかったことです。

### LLMが不要な処理の特徴

これらの処理に共通しているのは「入力に対して出力が一意に決まる」という点です。

日報生成の場合、`memory/YYYY-MM-DD.md`を読んで、決まった形式で箇条書きにまとめるだけです。テンプレートと入力データが決まっていれば、出力も決まります。そこに「自然言語の理解」も「曖昧な判断」も必要ありません。

DBの整合性チェックも同様です。「AテーブルとBテーブルで同じIDが存在するか」「ステータスの値が想定の範囲内か」——これはSQLかシンプルなスクリプトで書けます。ステータス更新に至っては、条件と更新先が決まっているので、単なるCRUD操作です。

こういった処理をAIセッションで実行すると何が起きるか。まず、トークンを消費します。処理の内容そのものより、「指示文を解釈する」「結果を自然言語で返す」部分でトークンが膨らみます。

次に、コンテキストを汚染します。「日報作って」「DBチェックして」「ステータス更新して」をセッション中に行うと、それらの作業内容がコンテキストに残り続けます。実際に判断が必要な処理を行うときに、前の作業の残骸がコンテキストを圧迫していました。

### jimuchoの誕生

この問題に気づいて、決定論的な処理をAIセッションから切り離すことにしました。その結果生まれたのがjimuchoです。

jimuchoはSQLite + REST APIのシンプルなシステムです。Webアプリというほどのものではありませんが、ブラウザからもアクセスできる管理画面を持っています。

```
http://localhost:3100
├── /api/projects     # プロジェクト管理
├── /api/activity     # 活動ログ
├── /api/daily-report # 日報生成（テンプレートベース）
└── /api/check        # 整合性チェック
```

日報生成は`/api/daily-report`にGETリクエストを送るだけで、その日の`memory/`ファイルを読んでテンプレートに流し込んだMarkdownが返ってきます。整合性チェックは`/api/check`でSQLクエリを実行して不整合があればリストで返します。

AIセッションがこれらにアクセスするとき、やることは「APIを叩いて結果を受け取る」だけです。「何をどう処理するか」をLLMが考える必要はありません。

```bash
# Before: AIセッションで逐次実行（コンテキスト消費大）
# 「今日の日報を作ってください。memory/2026-02-18.mdを読んで...」

# After: APIを叩くだけ
curl http://localhost:3100/api/daily-report?date=2026-02-18
```

AIの担当は「結果をどう使うか」という判断だけになり、処理そのものは手を離れました。

### Notion廃止もこの流れで起きた

jimuchoを作る前は、業務データの管理をNotionで行っていました。AIがNotionのAPIを叩いてページを読み書きする構成です。

Notionのレート制限は毎秒3リクエストです。バッチ処理をしようとすると詰まります。APIのレスポンスも「人間のUIを無理やりAPIにした」構造で、LLMには冗長です。1つのページを読むためのJSONに、LLMが必要としない情報が大量に含まれています。

```json
// Notion APIのレスポンス（一部）— 必要な情報の周りに大量のメタデータ
{
  "object": "page",
  "id": "xxxxxx",
  "created_time": "2024-01-01T00:00:00.000Z",
  "last_edited_time": "2024-01-02T00:00:00.000Z",
  "properties": {
    "Name": {
      "id": "title",
      "type": "title",
      "title": [{"type": "text", "text": {"content": "プロジェクトA"}}]
    }
  }
}

// jimucho APIのレスポンス — 必要なものだけ
{
  "id": 1,
  "name": "プロジェクトA",
  "status": "実装中",
  "estimated_hours": 8
}
```

SQLite + REST APIに変えてから、AI側のコンテキスト消費が目に見えて減りました。必要な情報だけを返すAPIを自分で設計できるので、「LLMが処理しやすい形」で情報を渡せます。

Notion廃止はjimuchoを作ったことの副次効果でしたが、こちらの方が体感的なインパクトは大きかったです。

### cronジョブとの連携

決定論的な処理をjimuchoに移したことで、もう1つ変化がありました。これらの処理をcronジョブとして自動化できるようになったことです。

以前はAIセッション中に「ついでに」実行していたため、AI側のセッション起動に依存していました。jimuchoが独立したサービスとして常時起動するようになってから、AIが動いていなくても基盤が機能します。

```bash
# 毎朝9時に整合性チェック（AIの起動不要）
0 9 * * * curl -s http://localhost:3100/api/check

# 毎週月曜に週次レポート生成
0 8 * * 1 curl -s http://localhost:3100/api/weekly-report
```

jimucho側で動く処理が増えるほど、AIセッションのコンテキストに余裕ができます。

### 分離の基準

決定論的に作れるかどうかの判断基準はシンプルです。「入力が同じなら出力も同じになるか」——これがYesなら、LLMを使う必要がありません。

逆に「文脈を読む」「曖昧さを解消する」「複数の選択肢を判断する」が必要な処理は、LLMにしかできない仕事です。日報のフォーマットを決めてしまえばLLM不要ですが、「今週の振り返りをして次のアクションを考えて」はLLMの仕事です。

この分離を意識してから、AIセッションのコンテキストが「本当に必要な判断」だけに使われるようになりました。

## 文書が増えるほど指示が守られなくなった

### ルールを書いたら守られると思っていた

AIエージェントに決まったルールを守らせる方法として、最初に思いつくのは「AGENTS.mdに書く」です。実際にそうしていました。

Discord報告のルール、日次メモリの書き方、コミットメッセージの形式、エスカレーション条件——これらをAGENTS.mdに追記し続けました。「書いてあれば守る」と思っていたからです。

ところが、運用を続けるほど守られないルールが増えていきました。

### 34KBへの膨張

AGENTS.mdとMEMORY.mdのサイズを計測してみたところ、合計34KBになっていました。

内訳はこんな感じです。

- 現在有効なルール: 約8KB
- 過去の検討メモ（「この方式を試したが〜という理由で廃止した」）: 約10KB
- 実績記録（「X月にY件完了」）: 約6KB
- 廃止されたルール（新しい方式に置き換えたが削除していない）: 約10KB

「役に立ちそうな情報」を書き続けた結果、現在有効なルールよりもノイズの方が多い文書になっていました。

### コンパクションの連鎖

Claudeのコンテキストウィンドウには上限があります。会話が長くなると、古いやり取りを自動で要約するコンパクションが走ります。

問題はここです。コンパクションは「何が重要か」をモデルが判断して要約します。セッション序盤に読み込んだAGENTS.mdのルールも、コンパクションの対象になりえます。

実際に起きた連鎖はこうです。

1. AGENTS.mdの肥大化 → コンパクションが発動しやすくなる
2. コンパクションが「途中経過をDiscordに書くな」ルールを要約で落とす
3. AIが作業途中にDiscordへ進捗投稿し始める
4. 指摘する → AIがルールを再追記 → AGENTS.mdがさらに肥大化
5. 1に戻る

「ルールを守らせるために書いた文書」が、「ルールが守られなくなる原因」になっていました。

### 5KBへの削減

悪循環を断ち切るために、AGENTS.mdとMEMORY.mdを全面的に見直しました。

方針はシンプルにしました。「今この瞬間に有効なルールだけを書く。それ以外は全部削る」。

削ったものは主に3種類です。

**過去の経緯メモ**は、daily memory（`memory/YYYY-MM-DD.md`）に移しました。「以前はNotionを使っていたが廃止した理由は〜」という記録は、AGENTS.mdに残す必要はありません。

**実績の記録**は、プロジェクト管理DB（jimucho）を見ればわかります。「X月にY件完了した」という情報をAGENTS.mdに書く理由がありません。

**廃止されたルール**は、そのまま削除しました。「以前はAという方式で、今はBという方式」と書くより、「Bという方式」とだけ書く方が明確です。

削減後のサイズは約5KBです。

```
削減前: AGENTS.md (22KB) + MEMORY.md (12KB) = 34KB
削減後: AGENTS.md (3KB)  + MEMORY.md (2KB)  = 5KB
```

### 削減後の変化

5KBに削減してから、ルール違反の頻度が減りました。

理由は単純だと思っています。「読まなければならない文書が短い」と、重要なルールが目に入りやすくなります。34KBを読むコンテキストと、5KBを読むコンテキストでは、残余のコンテキストに使える量が違います。

「軽く保つ」は反直感的です。情報を足すより引く方が難しいので、文書は自然に増えていきます。ただ、AIが毎回読むコンテキストファイルについては、「増やしたいなら削る」という方針を意識的に徹底しないと、あっという間に肥大化します。

### どこに何を書くかの整理

削減後に決めたのは「どこに何を書くか」のルールです。

| 情報の種類 | 書く場所 |
|-----------|---------|
| 現在有効なルール | AGENTS.md（5KB以内） |
| 今日の作業ログ | memory/YYYY-MM-DD.md |
| 長期的な文脈 | MEMORY.md（厳選） |
| PJ固有の情報 | 各PJのCLAUDE.md |

PJ固有の情報をAGENTS.mdに書くのは特に避けています。「PJ-Aのpage_idはxxxxxx」という情報をAGENTS.mdに書き始めると、PJが増えるたびに膨らみます。各プロジェクトのCLAUDE.mdに書けば、必要なときだけ読み込まれます。

### なぜ「ルールを増やすほど守られなくなる」のか

振り返ると、ルールの総量と遵守率は反比例していました。

1つの理由はコンパクションの問題ですが、もう1つ別の理由もあります。ルールが増えると、ルール同士が矛盾したり、どのルールを優先すべきか曖昧になります。34KBの文書の中には、当時の状況に合わせて書いたルールと、その後変えた方針が混在していました。AIはどちらを優先すべきか判断できず、結果的にルール違反のような動作をすることがありました。

具体例を挙げると、「Discord報告は完了時に1回だけ」というルールと、別の時期に書いた「長時間タスクは途中経過も報告して」というルールが共存していたことがあります。どちらを優先するかが曖昧で、AIは都度別の解釈をしていました。ルールを削減するときにこうした矛盾を洗い出し、「完了時に1回だけ。途中経過は作業ログに書く」と1文にまとめました。

「書いてあれば守る」ではなく「読める量に絞って書く、かつ矛盾なく書く」が正しかったです。

## 2つの問題に共通していたこと

振り返ると、2つの問題に共通するパターンがありました。「できるからやる」ではなく「やる必要があるかを先に判断する」という設計判断を怠っていた、ということです。

LLMは日報を生成できます。でも「生成する必要があるかどうか」を考えると、テンプレートと入力データが決まっているなら不要です。同じように、AGENTS.mdにルールを書けばAIはそれを読みます。ただ「何を書くべきかを選ばない」と、読む価値のある情報と読む必要のない情報が混在します。

どちらも「引き算の設計」が必要でした。足すことより引くことの方が、運用効率への影響が大きかったです。

jimuchoを作る前は「AIがなんとかしてくれる」という過信がありました。AIのコンテキストファイルを整理する前は「書いておけばいつか役立つ」という情報収集の惰性がありました。どちらも、実際に問題が表面化してからでないと気づきにくいことだとは思います。気づいた後は改善が速く、削減・分離の効果がはっきりわかりました。

## まとめ

2つの問題と対処をまとめます。

**LLMの無駄遣い問題**

- 決定論的な処理（日報生成、DB整合性チェック、ステータス更新）をAIセッションで実行していた
- 入力→出力が一意に決まる処理はLLMを使う必要がない
- jimuchoというSQLite + REST APIのシステムを作り、決定論的処理を移植した
- AIセッションのコンテキストが「本当に判断が必要な処理」だけに使われるようになった

**文書の肥大化問題**

- ルールを守らせようとAGENTS.md/MEMORY.mdに追記し続けた結果、34KBに膨張した
- コンパクションによるルール要約で、ルール違反の悪循環が発生した
- 「現在有効なルールだけ」を残して5KBに削減した
- ルール違反の頻度が減り、コンテキストに余裕ができた

どちらも「やれることをやる」ではなく「何をやらせるべきかを選ぶ」という判断を先にすべきだったという話です。

AIエージェントの運用は、ツールの設定だけでなく「何をAIに任せるか」という設計判断も含まれます。その設計が甘いと、AIの能力を活かすどころか、余分なコストを生む原因になります。

---

*次の記事では、1人で40件のプロジェクトを並走させるための「段階的委譲モデル」（Level 1〜3の自律判断設計）について書く予定です。*
